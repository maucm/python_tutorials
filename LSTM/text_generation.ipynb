{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Text Generator Using an RNN\n",
    "\n",
    "\n",
    "- The text from a book, chapter, etc can be thought of as a sequence. \n",
    "- RNN being based on sequential data can learn the sequences and generate new sequences \n",
    "- LTSM is an rnn network that helps avoid common problems\n",
    "\n",
    "the architecture is the following:\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*_YFtlUJG69dm6QLnFhYBoQ.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to learn:\n",
    "- Where to download a free corpus of text that you can use to train text generative models.\n",
    "- How to frame the problem of text sequences to a recurrent neural network generative model.\n",
    "- How to develop an LSTM to generate plausible text sequences for a given problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "from keras.layers import Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rous delightful hours, and with the kindest wishes, dedicated by his\\r\\naffectionate friend, the author.\\r\\n\\r\\n\\r\\n\\r\\n             '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load text \n",
    "articleUrl = requests.get(\"https://www.gutenberg.org/files/120/120-0.txt\")\n",
    "articleUrl.encoding = \"utf-8\"\n",
    "book_text = articleUrl.text\n",
    "book_text = book_text.lower()\n",
    "book_text[877:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_text = book_text[4300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a mapping to unique chars to ints\n",
    "\n",
    "chars = sorted(list(set(book_text)))\n",
    "chars_to_int = {c:i for i,c in enumerate(chars)}\n",
    "chars_to_int['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " '\\r',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '%',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " '@',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '“',\n",
       " '”']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book with 387306 chars and vocab is 57 unique chars\n"
     ]
    }
   ],
   "source": [
    "# summarize the data set\n",
    "n_chars = len(book_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Book with {} chars and vocab is {} unique chars\".format(n_chars,n_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### choosing how to define the training data \n",
    "- the book text will be split into subsequences of a 100 timesteps (t100) with a fixed length of 100 chars (100,100) 100 input vectors with a 100 timesteps\n",
    "- 100 timesteps of one char input(x) and followed by one char output(y)\n",
    "\n",
    "ex:\n",
    "\n",
    "<li>runni -->n</li>\n",
    "<li>unnin --> g</li>\n",
    "\n",
    "### in the kafka example:\n",
    "\n",
    "- after the 100 chars, comes one output the next char\n",
    "- each letter is a timestep\n",
    "- there are a 100 chars, thus a 100 input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\ufeffthe project gutenberg ebook of treasure island, by robert louis stevenson\\r\\n\\r\\nthis ebook is for the ', 'u')\n",
      "[60, 51, 39, 36, 2, 47, 49, 46, 41, 36, 34, 51, 2, 38, 52, 51, 36, 45, 33, 36, 49, 38, 2, 36, 33, 46, 46, 42, 2, 46, 37, 2, 51, 49, 36, 32, 50, 52, 49, 36, 2, 40, 50, 43, 32, 45, 35, 11, 2, 33, 56, 2, 49, 46, 33, 36, 49, 51, 2, 43, 46, 52, 40, 50, 2, 50, 51, 36, 53, 36, 45, 50, 46, 45, 1, 0, 1, 0, 51, 39, 40, 50, 2, 36, 33, 46, 46, 42, 2, 40, 50, 2, 37, 46, 49, 2, 51, 39, 36, 2]\n",
      "52\n",
      "('the project gutenberg ebook of treasure island, by robert louis stevenson\\r\\n\\r\\nthis ebook is for the u', 's')\n",
      "[51, 39, 36, 2, 47, 49, 46, 41, 36, 34, 51, 2, 38, 52, 51, 36, 45, 33, 36, 49, 38, 2, 36, 33, 46, 46, 42, 2, 46, 37, 2, 51, 49, 36, 32, 50, 52, 49, 36, 2, 40, 50, 43, 32, 45, 35, 11, 2, 33, 56, 2, 49, 46, 33, 36, 49, 51, 2, 43, 46, 52, 40, 50, 2, 50, 51, 36, 53, 36, 45, 50, 46, 45, 1, 0, 1, 0, 51, 39, 40, 50, 2, 36, 33, 46, 46, 42, 2, 40, 50, 2, 37, 46, 49, 2, 51, 39, 36, 2, 52]\n",
      "50\n",
      "('he project gutenberg ebook of treasure island, by robert louis stevenson\\r\\n\\r\\nthis ebook is for the us', 'e')\n",
      "[39, 36, 2, 47, 49, 46, 41, 36, 34, 51, 2, 38, 52, 51, 36, 45, 33, 36, 49, 38, 2, 36, 33, 46, 46, 42, 2, 46, 37, 2, 51, 49, 36, 32, 50, 52, 49, 36, 2, 40, 50, 43, 32, 45, 35, 11, 2, 33, 56, 2, 49, 46, 33, 36, 49, 51, 2, 43, 46, 52, 40, 50, 2, 50, 51, 36, 53, 36, 45, 50, 46, 45, 1, 0, 1, 0, 51, 39, 40, 50, 2, 36, 33, 46, 46, 42, 2, 40, 50, 2, 37, 46, 49, 2, 51, 39, 36, 2, 52, 50]\n",
      "36\n",
      "('e project gutenberg ebook of treasure island, by robert louis stevenson\\r\\n\\r\\nthis ebook is for the use', ' ')\n",
      "[36, 2, 47, 49, 46, 41, 36, 34, 51, 2, 38, 52, 51, 36, 45, 33, 36, 49, 38, 2, 36, 33, 46, 46, 42, 2, 46, 37, 2, 51, 49, 36, 32, 50, 52, 49, 36, 2, 40, 50, 43, 32, 45, 35, 11, 2, 33, 56, 2, 49, 46, 33, 36, 49, 51, 2, 43, 46, 52, 40, 50, 2, 50, 51, 36, 53, 36, 45, 50, 46, 45, 1, 0, 1, 0, 51, 39, 40, 50, 2, 36, 33, 46, 46, 42, 2, 40, 50, 2, 37, 46, 49, 2, 51, 39, 36, 2, 52, 50, 36]\n",
      "2\n",
      "(' project gutenberg ebook of treasure island, by robert louis stevenson\\r\\n\\r\\nthis ebook is for the use ', 'o')\n",
      "[2, 47, 49, 46, 41, 36, 34, 51, 2, 38, 52, 51, 36, 45, 33, 36, 49, 38, 2, 36, 33, 46, 46, 42, 2, 46, 37, 2, 51, 49, 36, 32, 50, 52, 49, 36, 2, 40, 50, 43, 32, 45, 35, 11, 2, 33, 56, 2, 49, 46, 33, 36, 49, 51, 2, 43, 46, 52, 40, 50, 2, 50, 51, 36, 53, 36, 45, 50, 46, 45, 1, 0, 1, 0, 51, 39, 40, 50, 2, 36, 33, 46, 46, 42, 2, 40, 50, 2, 37, 46, 49, 2, 51, 39, 36, 2, 52, 50, 36, 2]\n",
      "46\n",
      "('project gutenberg ebook of treasure island, by robert louis stevenson\\r\\n\\r\\nthis ebook is for the use o', 'f')\n",
      "[47, 49, 46, 41, 36, 34, 51, 2, 38, 52, 51, 36, 45, 33, 36, 49, 38, 2, 36, 33, 46, 46, 42, 2, 46, 37, 2, 51, 49, 36, 32, 50, 52, 49, 36, 2, 40, 50, 43, 32, 45, 35, 11, 2, 33, 56, 2, 49, 46, 33, 36, 49, 51, 2, 43, 46, 52, 40, 50, 2, 50, 51, 36, 53, 36, 45, 50, 46, 45, 1, 0, 1, 0, 51, 39, 40, 50, 2, 36, 33, 46, 46, 42, 2, 40, 50, 2, 37, 46, 49, 2, 51, 39, 36, 2, 52, 50, 36, 2, 46]\n",
      "37\n",
      "('roject gutenberg ebook of treasure island, by robert louis stevenson\\r\\n\\r\\nthis ebook is for the use of', ' ')\n",
      "[49, 46, 41, 36, 34, 51, 2, 38, 52, 51, 36, 45, 33, 36, 49, 38, 2, 36, 33, 46, 46, 42, 2, 46, 37, 2, 51, 49, 36, 32, 50, 52, 49, 36, 2, 40, 50, 43, 32, 45, 35, 11, 2, 33, 56, 2, 49, 46, 33, 36, 49, 51, 2, 43, 46, 52, 40, 50, 2, 50, 51, 36, 53, 36, 45, 50, 46, 45, 1, 0, 1, 0, 51, 39, 40, 50, 2, 36, 33, 46, 46, 42, 2, 40, 50, 2, 37, 46, 49, 2, 51, 39, 36, 2, 52, 50, 36, 2, 46, 37]\n",
      "2\n",
      "('oject gutenberg ebook of treasure island, by robert louis stevenson\\r\\n\\r\\nthis ebook is for the use of ', 'a')\n",
      "[46, 41, 36, 34, 51, 2, 38, 52, 51, 36, 45, 33, 36, 49, 38, 2, 36, 33, 46, 46, 42, 2, 46, 37, 2, 51, 49, 36, 32, 50, 52, 49, 36, 2, 40, 50, 43, 32, 45, 35, 11, 2, 33, 56, 2, 49, 46, 33, 36, 49, 51, 2, 43, 46, 52, 40, 50, 2, 50, 51, 36, 53, 36, 45, 50, 46, 45, 1, 0, 1, 0, 51, 39, 40, 50, 2, 36, 33, 46, 46, 42, 2, 40, 50, 2, 37, 46, 49, 2, 51, 39, 36, 2, 52, 50, 36, 2, 46, 37, 2]\n",
      "32\n",
      "('ject gutenberg ebook of treasure island, by robert louis stevenson\\r\\n\\r\\nthis ebook is for the use of a', 'n')\n",
      "[41, 36, 34, 51, 2, 38, 52, 51, 36, 45, 33, 36, 49, 38, 2, 36, 33, 46, 46, 42, 2, 46, 37, 2, 51, 49, 36, 32, 50, 52, 49, 36, 2, 40, 50, 43, 32, 45, 35, 11, 2, 33, 56, 2, 49, 46, 33, 36, 49, 51, 2, 43, 46, 52, 40, 50, 2, 50, 51, 36, 53, 36, 45, 50, 46, 45, 1, 0, 1, 0, 51, 39, 40, 50, 2, 36, 33, 46, 46, 42, 2, 40, 50, 2, 37, 46, 49, 2, 51, 39, 36, 2, 52, 50, 36, 2, 46, 37, 2, 32]\n",
      "45\n",
      "('ect gutenberg ebook of treasure island, by robert louis stevenson\\r\\n\\r\\nthis ebook is for the use of an', 'y')\n",
      "[36, 34, 51, 2, 38, 52, 51, 36, 45, 33, 36, 49, 38, 2, 36, 33, 46, 46, 42, 2, 46, 37, 2, 51, 49, 36, 32, 50, 52, 49, 36, 2, 40, 50, 43, 32, 45, 35, 11, 2, 33, 56, 2, 49, 46, 33, 36, 49, 51, 2, 43, 46, 52, 40, 50, 2, 50, 51, 36, 53, 36, 45, 50, 46, 45, 1, 0, 1, 0, 51, 39, 40, 50, 2, 36, 33, 46, 46, 42, 2, 40, 50, 2, 37, 46, 49, 2, 51, 39, 36, 2, 52, 50, 36, 2, 46, 37, 2, 32, 45]\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of inputs to output pairs encoded as integers\n",
    "# example\n",
    "seq_len = 100\n",
    "for i in range(0,n_chars - seq_len)[:10]:\n",
    "    seq_in = book_text[i: i+seq_len]\n",
    "    seq_out = book_text[i+seq_len]\n",
    "    print((seq_in,seq_out))\n",
    "    print([chars_to_int[char] for char in seq_in])\n",
    "    print(chars_to_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387206\n",
      "387206\n",
      "number of patterns 387206\n"
     ]
    }
   ],
   "source": [
    "## actual input to output pairs encoded as ints\n",
    "seq_len = 100\n",
    "data_x = [[chars_to_int[char] for char in book_text[i: i+seq_len]] for i in range(0,n_chars - seq_len)]\n",
    "data_y = [[chars_to_int[char] for char in book_text[i+seq_len]] for i in range(0,n_chars - seq_len)]\n",
    "print(len(data_x))\n",
    "print(len(data_y))\n",
    "print(\"number of patterns {}\".format(len(data_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### the data:\n",
    "- the list of input sequences must be in [samples,time_steps,features]\n",
    "- the integers needs to be rescaled between 0 and 1, to make it easier for the network to learn \n",
    "- convert the output into OneHotEnconding - sparse vector with a len of 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387206, 100, 1)\n",
      "0.0\n",
      "0.98245615\n",
      "[0.57894737 0.57894737 0.80701756 0.01754386 0.         0.01754386\n",
      " 0.         0.01754386 0.         0.01754386 0.         0.01754386\n",
      " 0.         0.2631579  0.01754386 0.         0.01754386 0.\n",
      " 0.84210527 0.6315789  0.57894737 0.03508772 0.75438595 0.7017544\n",
      " 0.5614035  0.03508772 0.8245614  0.57894737 0.50877196 0.19298245\n",
      " 0.5614035  0.75438595 0.61403507 0.03508772 0.50877196 0.84210527\n",
      " 0.03508772 0.84210527 0.6315789  0.57894737 0.03508772 0.50877196\n",
      " 0.5614035  0.71929824 0.64912283 0.80701756 0.50877196 0.7017544\n",
      " 0.03508772 0.5263158  0.57894737 0.7368421  0.5263158  0.75438595\n",
      " 0.8947368  0.01754386 0.         0.01754386 0.         0.01754386\n",
      " 0.         0.8245614  0.7894737  0.8596491  0.64912283 0.80701756\n",
      " 0.57894737 0.03508772 0.84210527 0.80701756 0.57894737 0.7017544\n",
      " 0.50877196 0.8947368  0.7368421  0.57894737 0.9298246  0.1754386\n",
      " 0.03508772 0.5614035  0.80701756 0.21052632 0.03508772 0.7017544\n",
      " 0.64912283 0.877193   0.57894737 0.8245614  0.57894737 0.9298246\n",
      " 0.1754386  0.03508772 0.50877196 0.7368421  0.5614035  0.03508772\n",
      " 0.84210527 0.6315789  0.57894737 0.03508772]\n"
     ]
    }
   ],
   "source": [
    "# reshape x\n",
    "num_patterns = len(data_x)\n",
    "x_train = np.reshape(data_x,(num_patterns,seq_len,1))\n",
    "print(x_train.shape)\n",
    "\n",
    "# scale x \n",
    "x_train = (x_train / float(n_vocab)).astype('float32')\n",
    "print(x_train.min())\n",
    "print(x_train.max())\n",
    "print(x_train[:1].ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(387206, 57)\n"
     ]
    }
   ],
   "source": [
    "# one hot enconde the output vector\n",
    "y_train = np_utils.to_categorical(data_y)\n",
    "print(y_train[:2])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100, 256)          264192    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 57)                14649     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 57)                0         \n",
      "=================================================================\n",
      "Total params: 804,153\n",
      "Trainable params: 804,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "        # THE MODEL #\n",
    "################################\n",
    "input_shape = (x_train.shape[1],x_train.shape[2])\n",
    "num_labels = y_train.shape[1]\n",
    "batch_size = 256\n",
    "hlayers = 256\n",
    "dropout = .25\n",
    "\n",
    "# model RNN \n",
    "model = Sequential()\n",
    "model.add(LSTM(units=hlayers,input_shape=input_shape,return_sequences=True))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(LSTM(units=256))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfile = \"w-improvement-{epoch:02d}-{acc:.4f}.hdf5\"\\ncheckpoint = ModelCheckpoint(file,monitor=\\'acc\\', verbose=1, save_best_only=True,mode=\\'max\\')\\ncallback = [checkpoint]\\n\\n\\nmodel.fit(x_train,y_train,batch_size=batch_size,epochs=1,callbacks=callback)\\nprint(\"Finished Training\")\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"rmsprop\",metrics=[\"accuracy\"])\n",
    "\n",
    "# Define a checkpoint to save the weights if improvement in loss is seen at the end\n",
    "# the model will be loaded with the best set of weights\n",
    "\"\"\"\n",
    "file = \"w-improvement-{epoch:02d}-{acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file,monitor='acc', verbose=1, save_best_only=True,mode='max')\n",
    "callback = [checkpoint]\n",
    "\n",
    "\n",
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=1,callbacks=callback)\n",
    "print(\"Finished Training\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generating text \n",
    "\n",
    "file_w = \"w-improvement-93-0.5862.hdf5\"\n",
    "model.load_weights(file_w)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"rmsprop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary to convert back to numbers\n",
    "\n",
    "int_to_char = {i:c for i,c in enumerate(chars)}\n",
    "int_to_char[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Generation \n",
    "- start with a random seed sequence as input and genereate the next character using that seed sequence, and remove first char and append new char and so on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " behind me over my shoulder, began to\n",
      "retrace my steps in the direction of the boats.\n",
      "\n",
      "instantly \n",
      "i was on the streation of the ship shat had she coatt was\n",
      "still silver and the same time and she was off a mone startler of his\n",
      "andiorage, and the shought of the ship was a bliar of the ship's mane,\n",
      "i was stre that the same might of his cape, and the shore were all was\n",
      "still sirenng and shere and shen and the sea certied on the stockade,\n",
      "and the shore realan was struck and sook a ship of the stockade, and\n",
      "the same moment the mort coats were all was on the south- and the should\n",
      "of the stoc"
     ]
    }
   ],
   "source": [
    "# random seed\n",
    "seed = np.random.randint(0,len(data_x)-1)\n",
    "seed\n",
    "pat = data_x[seed]\n",
    "\n",
    "# generate chars\n",
    "print(\"\".join([int_to_char[val] for val in pat]))\n",
    "for i in range(500):\n",
    "    x = np.reshape(pat,(1,len(data_x[0]),1)) \n",
    "    x = x / float(n_vocab)   \n",
    "    # char prediction\n",
    "    prediction = model.predict(x)\n",
    "    pred_char = np.argmax(prediction)\n",
    "    char_to_text = int_to_char[pred_char]\n",
    "    sys.stdout.write(char_to_text)\n",
    "    pat.append(pred_char)\n",
    "    pat = pat[1:len(pat)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
